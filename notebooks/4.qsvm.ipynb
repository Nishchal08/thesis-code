{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa54d59a",
   "metadata": {},
   "source": [
    "# Step 5f — QSVM with **3 qubits** and **8 PCA features** (data re‑upload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ff905d",
   "metadata": {},
   "source": [
    "This notebook builds a **quantum kernel SVM (QSVM)** using **3 qubits** while ingesting **8 PCA features** via **data re‑uploading**.  \n",
    "We compute a **fidelity kernel** \\(k(x,z) = |\\langle \\phi(x) | \\phi(z) \\rangle|^2\\) with a fixed feature map \\(U(x)\\) and train an SVM on the **precomputed** kernel.\n",
    "\n",
    "**Why re‑uploading?** It lets us encode more features than qubits by feeding features across multiple single‑qubit rotation blocks (RY → RZ → RX) on the same 3 wires.\n",
    "\n",
    "**Inputs required** (from your PCA step):  \n",
    "- `../data/processed/pca8_train.csv`  \n",
    "- `../data/processed/pca8_test.csv`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97f7c1d",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e807beda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "BASE_DATA = Path(\"../data\")\n",
    "PROCESSED_DIR = BASE_DATA / \"processed\"\n",
    "\n",
    "TRAIN_CSV = PROCESSED_DIR / \"pca8_train.csv\"\n",
    "TEST_CSV  = PROCESSED_DIR / \"pca8_test.csv\"\n",
    "\n",
    "PC_COLS = [\"PC1\",\"PC2\",\"PC3\",\"PC4\",\"PC5\",\"PC6\",\"PC7\",\"PC8\"]\n",
    "N_QUBITS = 3\n",
    "ALL_CLASSES = [\"angry\", \"fearful\", \"happy\", \"neutral\", \"sad\"]\n",
    "\n",
    "# SVM / kernel settings\n",
    "SVM_C = 1.0          # regularization strength\n",
    "ANGLE_CLIP = math.pi # map PCs to [-pi, pi] using TRAIN max-abs\n",
    "K_SAVE = True        # save kernel matrices to disk\n",
    "\n",
    "OUT_DIR = PROCESSED_DIR / \"qsvm3_8pca_kernel\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"TRAIN_CSV:\", TRAIN_CSV.resolve())\n",
    "print(\"TEST_CSV :\", TEST_CSV.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104cb568",
   "metadata": {},
   "source": [
    "## Verify inputs exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf662f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "missing = []\n",
    "if not TRAIN_CSV.exists(): missing.append(str(TRAIN_CSV))\n",
    "if not TEST_CSV.exists():  missing.append(str(TEST_CSV))\n",
    "if missing:\n",
    "    raise SystemExit(\"Missing required file(s):\\n  - \" + \"\\n  - \".join(missing))\n",
    "else:\n",
    "    print(\"PCA(8) files found ✓\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbdab1d",
   "metadata": {},
   "source": [
    "## Imports & utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2b920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json, random, time\n",
    "import numpy as onp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pennylane as qml\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEED = 7\n",
    "random.seed(SEED); onp.random.seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "def load_data(train_csv, test_csv, pc_cols, valid_classes):\n",
    "    tr = pd.read_csv(train_csv); te = pd.read_csv(test_csv)\n",
    "    tr = tr[tr[\"emotion\"].isin(valid_classes)].reset_index(drop=True)\n",
    "    te = te[te[\"emotion\"].isin(valid_classes)].reset_index(drop=True)\n",
    "    for col in pc_cols + [\"emotion\"]:\n",
    "        assert col in tr.columns and col in te.columns, f\"Missing column: {col}\"\n",
    "    return tr, te\n",
    "\n",
    "def build_angle_scaler(train_df, pc_cols, clip=np.pi):\n",
    "    scales = {}\n",
    "    for k in pc_cols:\n",
    "        m = float(train_df[k].abs().max())\n",
    "        scales[k] = {\"denom\": max(1e-8, 1.1*m), \"clip\": clip}\n",
    "    return scales\n",
    "\n",
    "def apply_angle_scaler(df, pc_cols, scales):\n",
    "    X = df[pc_cols].to_numpy(onp.float32)\n",
    "    for j, key in enumerate(pc_cols):\n",
    "        d = scales[key][\"denom\"]; c = scales[key][\"clip\"]\n",
    "        X[:, j] = np.clip((X[:, j] / d) * c, -c, c)\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c12af38",
   "metadata": {},
   "source": [
    "## Quantum device and **feature map** U(x) (re‑uploading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830b87ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Robust device: try lightning, else default.qubit\n",
    "try:\n",
    "    dev = qml.device(\"lightning.qubit\", wires=N_QUBITS, shots=None)\n",
    "    print(\"Using lightning.qubit ✅\")\n",
    "except Exception as e:\n",
    "    print(\"Falling back to default.qubit due to:\", repr(e))\n",
    "    dev = qml.device(\"default.qubit\", wires=N_QUBITS, shots=None)\n",
    "    print(\"Using default.qubit ✅\")\n",
    "\n",
    "def feature_map(x):\n",
    "    \"\"\"Fixed data-encoding circuit U(x) on N_QUBITS=3 with 8 features via re-uploading.\n",
    "    Blocks:\n",
    "      1) RY on q0..q2 using x1..x3\n",
    "      2) RZ on q0..q2 using x4..x6\n",
    "      3) RX on q0..q1 using x7..x8 (q2 gets 0)\n",
    "    Interleave simple entangling rings (CZ + IsingZZ with data-coupled angles).\n",
    "    \"\"\"\n",
    "    # Block 1: RY\n",
    "    qml.RY(x[0], wires=0); qml.RY(x[1], wires=1); qml.RY(x[2], wires=2)\n",
    "    # Entangle\n",
    "    qml.CZ(wires=[0,1]); qml.CZ(wires=[1,2]); qml.CZ(wires=[2,0])\n",
    "    # Block 2: RZ\n",
    "    qml.RZ(x[3], wires=0); qml.RZ(x[4], wires=1); qml.RZ(x[5], wires=2)\n",
    "    # ZZ ring with data-coupled angles (product terms encourage nonlinearity)\n",
    "    qml.IsingZZ(0.25*(x[0]*x[3]), wires=[0,1])\n",
    "    qml.IsingZZ(0.25*(x[1]*x[4]), wires=[1,2])\n",
    "    qml.IsingZZ(0.25*(x[2]*x[5]), wires=[2,0])\n",
    "    # Block 3: RX (x7,x8; q2 left at 0)\n",
    "    qml.RX(x[6], wires=0); qml.RX(x[7], wires=1)\n",
    "    # Final CZ ring\n",
    "    qml.CZ(wires=[0,1]); qml.CZ(wires=[1,2]); qml.CZ(wires=[2,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8777face",
   "metadata": {},
   "source": [
    "## Fidelity kernel k(x,z) = |⟨φ(x)|φ(z)⟩|²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a412e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@qml.qnode(dev)\n",
    "def kernel_circuit(x, z):\n",
    "    # Prepare |phi(z)> = U(z)|0>\n",
    "    feature_map(z)\n",
    "    # Apply U(x)†\n",
    "    qml.adjoint(feature_map)(x)\n",
    "    # Probability of |0..0> equals |⟨phi(x)|phi(z)⟩|^2\n",
    "    return qml.probs(wires=range(N_QUBITS))\n",
    "\n",
    "def fidelity_kernel(x, z):\n",
    "    probs = kernel_circuit(x, z)\n",
    "    return float(probs[0])  # prob of all-zeros\n",
    "\n",
    "def compute_kernel_matrix(A, B, desc=\"K\"):\n",
    "    \"\"\"Compute K[i,j] = k(A[i], B[j]) with progress.\"\"\"\n",
    "    n, m = len(A), len(B)\n",
    "    K = np.empty((n, m), dtype=np.float64)\n",
    "    t0 = time.time()\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            K[i, j] = fidelity_kernel(A[i], B[j])\n",
    "        if (i+1) % max(1, n//10) == 0 or i == n-1:\n",
    "            elapsed = time.time()-t0\n",
    "            print(f\"{desc}: row {i+1}/{n}  (elapsed {elapsed:.1f}s)\", end=\"\\r\")\n",
    "    print(f\"\\n{desc} done in {time.time()-t0:.1f}s; shape={K.shape}\")\n",
    "    return K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ecf696",
   "metadata": {},
   "source": [
    "## Load data, scale angles, and encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2848338",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df, test_df = load_data(TRAIN_CSV, TEST_CSV, PC_COLS, ALL_CLASSES)\n",
    "\n",
    "scales = build_angle_scaler(train_df, PC_COLS, clip=ANGLE_CLIP)\n",
    "X_train = apply_angle_scaler(train_df, PC_COLS, scales).astype(np.float64)\n",
    "X_test  = apply_angle_scaler(test_df,  PC_COLS, scales).astype(np.float64)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(train_df[\"emotion\"].values)\n",
    "y_test  = le.transform(test_df[\"emotion\"].values)\n",
    "\n",
    "print(\"Classes:\", list(le.classes_))\n",
    "print(\"X_train:\", X_train.shape, \"X_test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19af3057",
   "metadata": {},
   "source": [
    "## Compute quantum kernels (train & test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7f2e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "K_train = compute_kernel_matrix(X_train, X_train, desc=\"K_train\")\n",
    "K_test  = compute_kernel_matrix(X_test,  X_train, desc=\"K_test \")\n",
    "\n",
    "if K_SAVE:\n",
    "    np.save(OUT_DIR / \"K_train.npy\", K_train)\n",
    "    np.save(OUT_DIR / \"K_test.npy\",  K_test)\n",
    "    print(\"Saved kernels to:\", (OUT_DIR / \"K_train.npy\").resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246a00c8",
   "metadata": {},
   "source": [
    "## Train SVM (precomputed kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc70acfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svm = SVC(kernel=\"precomputed\", C=SVM_C, decision_function_shape=\"ovr\")\n",
    "svm.fit(K_train, y_train)\n",
    "\n",
    "yhat = svm.predict(K_test)\n",
    "acc = accuracy_score(y_test, yhat)\n",
    "print(\"Test accuracy:\", round(acc, 3))\n",
    "\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, yhat, target_names=le.classes_))\n",
    "print(\"Confusion matrix (rows=true, cols=pred):\\n\", confusion_matrix(y_test, yhat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34ad634",
   "metadata": {},
   "source": [
    "## (Optional) Visualize K_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4419f0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.imshow(K_train, aspect='auto')\n",
    "plt.title(\"K_train (quantum fidelity kernel)\")\n",
    "plt.colorbar(); plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ee0535",
   "metadata": {},
   "source": [
    "## References (encoding more features with fewer qubits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3639edca",
   "metadata": {},
   "source": [
    "\n",
    "- **Data re‑uploading** (encode features across repeated blocks on the same qubits): Pérez‑Salinas et al., *Data re‑uploading for a universal quantum classifier* (2019/2020).  \n",
    "- **Quantum kernels / QSVM**: Havlíček et al., *Supervised learning with quantum‑enhanced feature spaces* (Nature, 2019); Schuld & Killoran, *Quantum machine learning in feature Hilbert spaces* (PRL, 2019).\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
