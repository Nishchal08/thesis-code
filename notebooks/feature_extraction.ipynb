{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d581e2ce",
   "metadata": {},
   "source": [
    "\n",
    "# Step 2 ‚Äî Acoustic Feature Extraction (16‚ÄëD per Utterance)\n",
    "\n",
    "This notebook computes a compact **prosodic + spectral** feature vector for each processed audio file:\n",
    "\n",
    "- **MFCCs (13):** mean across time of coefficients **0‚Äì12** (0th ‚âà log‚Äëenergy)\n",
    "- **Pitch (F0):** mean over voiced frames (unvoiced ‚Üí ignored; all‚Äëunvoiced ‚Üí 0)\n",
    "- **Energy (RMS):** mean RMS\n",
    "- **Spectral Centroid:** mean centroid (Hz)\n",
    "\n",
    "**Framing:** 25 ms window, 10 ms hop, **Hamming** window; `n_fft=512`, `n_mels=40`.  \n",
    "**Input:** WAVs at **16 kHz** from `data/processed/<emotion>/[Actor_XX]/...`.  \n",
    "**Output:**  \n",
    "- `data/processed/features_16d.csv`  \n",
    "- `data/processed/features_16d_scaled.csv` (z‚Äëscored)  \n",
    "- `data/processed/scaler_standard.pkl` (for reuse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344099b0",
   "metadata": {},
   "source": [
    "## Install (run if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb92508",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %pip install librosa soundfile numpy pandas tqdm scikit-learn joblib matplotlib scipy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b463ff",
   "metadata": {},
   "source": [
    "## Config (paths + analysis params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a70e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# üìÅ Place this notebook in thesis_code/notebooks/\n",
    "# Default data root (sibling of notebooks/)\n",
    "BASE_DATA = Path(\"../data\")\n",
    "\n",
    "# If you run this from somewhere else, set an absolute path instead:\n",
    "# BASE_DATA = Path(\"/Users/nishchalpokhrel/Documents/project/thesis_code/data\")\n",
    "\n",
    "PROCESSED_DIR       = BASE_DATA / \"processed\"\n",
    "FEATURES_CSV        = PROCESSED_DIR / \"features_16d.csv\"\n",
    "FEATURES_SCALED_CSV = PROCESSED_DIR / \"features_16d_scaled.csv\"\n",
    "SCALER_PATH         = PROCESSED_DIR / \"scaler_standard.pkl\"\n",
    "\n",
    "# Analysis parameters (16 kHz audio from Step 1)\n",
    "SR = 16000\n",
    "FRAME_LEN_MS = 25\n",
    "HOP_MS       = 10\n",
    "\n",
    "win_length = int(SR * FRAME_LEN_MS / 1000.0)  # 400\n",
    "hop_length = int(SR * HOP_MS / 1000.0)        # 160\n",
    "n_fft = 512\n",
    "n_mfcc = 13\n",
    "n_mels = 40\n",
    "\n",
    "# Pitch range for speech (Hz)\n",
    "F0_MIN_HZ = 50.0\n",
    "F0_MAX_HZ = 500.0\n",
    "\n",
    "print(\"BASE_DATA     =\", BASE_DATA.resolve())\n",
    "print(\"PROCESSED_DIR =\", PROCESSED_DIR.resolve())\n",
    "print(\"win/hop (samples) =\", win_length, hop_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aee408a",
   "metadata": {},
   "source": [
    "## Imports & helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d95c7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import librosa, soundfile as sf\n",
    "from scipy.signal import resample_poly  # robust resampling (no resampy dependency)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "def safe_load_mono(path: Path, sr_expected: int):\n",
    "    \"\"\"Read WAV ‚Üí mono float32; resample to sr_expected if needed with polyphase.\"\"\"\n",
    "    y, sr = sf.read(str(path), always_2d=False)\n",
    "    if y.ndim > 1:\n",
    "        y = y.mean(axis=1)\n",
    "    y = y.astype(np.float32, copy=False)\n",
    "    if sr != sr_expected:\n",
    "        g = math.gcd(sr, sr_expected)\n",
    "        up, down = sr_expected // g, sr // g\n",
    "        y = resample_poly(y, up, down)\n",
    "        sr = sr_expected\n",
    "    return y, sr\n",
    "\n",
    "def mean_ignore_nan(x, fallback=0.0):\n",
    "    x = np.asarray(x)\n",
    "    if x.size == 0 or np.all(np.isnan(x)):\n",
    "        return float(fallback)\n",
    "    return float(np.nanmean(x))\n",
    "\n",
    "def extract_features_one(y, sr):\n",
    "    \"\"\"Return 16‚ÄëD: 13 MFCC means (0‚Äì12), mean pitch, mean RMS, mean centroid.\"\"\"\n",
    "    # MFCCs with Hamming window\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y=y, sr=sr, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length,\n",
    "        win_length=win_length, window='hamming', n_mels=n_mels, center=True\n",
    "    )  # (13, T)\n",
    "    mfcc_means = mfcc.mean(axis=1)\n",
    "\n",
    "    # Pitch via pYIN (NaN on unvoiced)\n",
    "    try:\n",
    "        f0, _, _ = librosa.pyin(\n",
    "            y, fmin=F0_MIN_HZ, fmax=F0_MAX_HZ, sr=sr,\n",
    "            frame_length=max(1024, n_fft), hop_length=hop_length, center=True\n",
    "        )\n",
    "        pitch_mean = mean_ignore_nan(f0, fallback=0.0)\n",
    "    except Exception:\n",
    "        pitch_mean = 0.0\n",
    "\n",
    "    # Energy (RMS)\n",
    "    rms = librosa.feature.rms(\n",
    "        y=y, frame_length=win_length, hop_length=hop_length, center=True\n",
    "    )  # (1, T)\n",
    "    rms_mean = float(rms.mean())\n",
    "\n",
    "    # Spectral centroid (Hz)\n",
    "    centroid = librosa.feature.spectral_centroid(\n",
    "        y=y, sr=sr, n_fft=n_fft, hop_length=hop_length,\n",
    "        win_length=win_length, window='hamming', center=True\n",
    "    )  # (1, T)\n",
    "    centroid_mean = float(centroid.mean())\n",
    "\n",
    "    feats = {f\"mfcc_{i}\": float(mfcc_means[i]) for i in range(n_mfcc)}\n",
    "    feats.update({\"pitch_mean\": pitch_mean, \"rms_mean\": rms_mean, \"centroid_mean\": centroid_mean})\n",
    "    return feats\n",
    "\n",
    "def parse_labels_from_processed_path(path: Path, processed_root: Path):\n",
    "    \"\"\"processed/<emotion>/Actor_XX/filename.wav  ‚Üí (emotion, actor)\"\"\"\n",
    "    parts = path.relative_to(processed_root).parts\n",
    "    emotion = parts[0] if len(parts) >= 1 else \"\"\n",
    "    actor = parts[1] if len(parts) >= 2 and parts[1].lower().startswith(\"actor\") else \"\"\n",
    "    return emotion, actor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80bc33c",
   "metadata": {},
   "source": [
    "## Debug ‚Äî list the processed WAVs we can see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3156d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wav_files = list(PROCESSED_DIR.rglob(\"*.wav\")) + list(PROCESSED_DIR.rglob(\"*.WAV\"))\n",
    "print(f\"Found {len(wav_files)} processed WAV files under {PROCESSED_DIR}\")\n",
    "for p in sorted(wav_files)[:12]:\n",
    "    print(\"‚Ä¢\", p)\n",
    "if not wav_files:\n",
    "    raise SystemExit(\n",
    "        \"‚ö†Ô∏è No processed WAVs found. Set BASE_DATA correctly (e.g., BASE_DATA = Path('/Users/.../thesis_code/data')) \"\n",
    "        \"and ensure Step 1 wrote to data/processed/<emotion>/...\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b8b22b",
   "metadata": {},
   "source": [
    "## Extract features (16‚ÄëD) and save CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6e2a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows = []\n",
    "for wav in tqdm(sorted(wav_files), desc=\"Extracting\"):\n",
    "    try:\n",
    "        y, sr = safe_load_mono(wav, SR)\n",
    "        feats = extract_features_one(y, sr)\n",
    "        emotion, actor = parse_labels_from_processed_path(wav, PROCESSED_DIR)\n",
    "        row = {\"path\": str(wav), \"emotion\": emotion, \"actor\": actor}\n",
    "        row.update(feats)\n",
    "        rows.append(row)\n",
    "    except Exception as e:\n",
    "        rows.append({\"path\": str(wav), \"emotion\": None, \"actor\": None, \"error\": str(e)})\n",
    "\n",
    "features = pd.DataFrame(rows)\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "features.to_csv(FEATURES_CSV, index=False)\n",
    "print(\"Saved ‚Üí\", FEATURES_CSV.resolve())\n",
    "features.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1d5d11",
   "metadata": {},
   "source": [
    "## Standardize (z‚Äëscore) & save scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9833d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "feat_cols = [f\"mfcc_{i}\" for i in range(n_mfcc)] + [\"pitch_mean\", \"rms_mean\", \"centroid_mean\"]\n",
    "\n",
    "ok = features.dropna(subset=feat_cols).copy()\n",
    "if len(ok):\n",
    "    scaler = StandardScaler()\n",
    "    ok[feat_cols] = scaler.fit_transform(ok[feat_cols])\n",
    "    ok.to_csv(FEATURES_SCALED_CSV, index=False)\n",
    "    joblib.dump(scaler, SCALER_PATH)\n",
    "    print(\"Saved scaled ‚Üí\", FEATURES_SCALED_CSV.resolve())\n",
    "    print(\"Saved scaler ‚Üí\", SCALER_PATH.resolve())\n",
    "    ok[[\"emotion\",\"actor\"] + feat_cols].head(3)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No complete rows to standardize. Check extraction output.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa5fa78",
   "metadata": {},
   "source": [
    "## (Optional) Quick sanity plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678a3495",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if len(features):\n",
    "    plt.figure()\n",
    "    features[\"pitch_mean\"].dropna().hist(bins=40)\n",
    "    plt.title(\"Pitch (mean F0) distribution\")\n",
    "    plt.xlabel(\"Hz\"); plt.ylabel(\"Count\")\n",
    "    plt.show()\n",
    "\n",
    "    if 'mfcc_1' in features.columns:\n",
    "        plt.figure()\n",
    "        features['mfcc_1'].dropna().hist(bins=40)\n",
    "        plt.title(\"MFCC_1 distribution\")\n",
    "        plt.xlabel(\"Value\"); plt.ylabel(\"Count\")\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No features to plot yet.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
